{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNXnsOv9xfTrqX0F4864YGl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tn_35CwcP_bQ","executionInfo":{"status":"ok","timestamp":1730607611758,"user_tz":-330,"elapsed":19134,"user":{"displayName":"Sathvika Sathvi","userId":"03386786111378409958"}},"outputId":"5cd33586-4c15-4067-af51-8c443602559c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import random\n","\n","def calculate_min_reward(C, R):\n","    P = np.multiply(C, R)\n","    non_zero_elements = P[C == 1]\n","    return np.min(non_zero_elements) if len(non_zero_elements) > 0 else 0\n","\n","def simulated_annealing(C, R, initial_tem  p, cooling_rate, max_iterations):\n","    current_solution = np.random.rand(*R.shape) * 100  # Random initial solution in [0, 100]\n","    current_reward = calculate_min_reward(C, current_solution)\n","    best_solution = np.copy(current_solution)\n","    best_reward = current_reward\n","\n","    temperature = initial_temp\n","\n","    for iteration in range(max_iterations):\n","        # Create a new solution by perturbing the current solution\n","        new_solution = current_solution + (np.random.rand(*R.shape) - 0.5) * temperature\n","        new_solution = np.clip(new_solution, 0, 100)  # Keep within [0, 100]\n","\n","        new_reward = calculate_min_reward(C, new_solution)\n","\n","        # If the new solution is better, accept it\n","        if new_reward > current_reward:\n","            current_solution = new_solution\n","            current_reward = new_reward\n","\n","            # Check if it's the best solution found\n","            if new_reward > best_reward:\n","                best_solution = new_solution\n","                best_reward = new_reward\n","        else:\n","            # Accept with a probability based on temperature\n","            if random.uniform(0, 1) < np.exp((new_reward - current_reward) / temperature):\n","                current_solution = new_solution\n","                current_reward = new_reward\n","\n","        # Decrease the temperature\n","        temperature *= cooling_rate\n","\n","    return best_solution, best_reward\n","\n","# Load the channel matrix and reward matrix from CSV files\n","C_full = pd.read_csv(\"/content/drive/MyDrive/finalyr/channel_matrix.csv\", header=None).values  # Load the channel matrix\n","R_full = pd.read_csv(\"/content/drive/MyDrive/finalyr/reward_matrix.csv\", header=None).values  # Load the reward matrix\n","\n","# Select a subset size (for example, 10x10)\n","subset_size = 10  # Set this to 10 for a 10x10 matrix\n","C = C_full[:subset_size, :subset_size]\n","R = R_full[:subset_size, :subset_size]\n","\n","# Define parameters for simulated annealing\n","initial_temperature = 1000\n","cooling_rate = 0.99\n","max_iterations = 1000\n","\n","# Run simulated annealing\n","best_solution, best_reward = simulated_annealing(C, R, initial_temperature, cooling_rate, max_iterations)\n","\n","# Output results\n","print(\"Best Reward Matrix (Simulated Annealing):\")\n","print(best_solution)\n","print(\"Best Minimum Reward Achieved:\", best_reward)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C9lOtzlkQGav","executionInfo":{"status":"ok","timestamp":1730607749501,"user_tz":-330,"elapsed":1467,"user":{"displayName":"Sathvika Sathvi","userId":"03386786111378409958"}},"outputId":"c5a4ee7a-7e22-4dc7-ca26-7731384e1a1a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Best Reward Matrix (Simulated Annealing):\n","[[ 8.89327162 79.65757087 19.04990356 79.30670339 94.54034533 22.57115859\n","  56.90702114 19.13523867 99.87682583 97.19991116]\n"," [92.37875926 98.44580737 30.18088052 61.34521212 12.12015114 11.51874799\n","  98.19040982 59.73800164 72.11052857 58.23781407]\n"," [51.31130713 37.73876315 31.35492671 29.35778831 25.64024978 70.64489796\n","  11.75758767 81.2230183  98.49591395 19.81318433]\n"," [12.61729306 84.45499181 59.11130931 11.36199828 30.06394161 55.21839578\n","  61.65906172  9.8770432  27.0771154  95.81514616]\n"," [82.84783695 70.32897557 81.23926325 19.10674115 89.67392263 78.19011743\n","  29.6356518  12.94990716 13.34705518  9.64746671]\n"," [88.1313204  81.72957956  1.42037316 51.62421906  5.84088281  8.86632547\n","  33.19554921 29.01507592 13.2236168  24.22548408]\n"," [52.33191693 95.82331618 15.22369098 43.38408698 68.14875849 51.0168351\n","  50.95207244 58.53798756 85.84550259 62.53912779]\n"," [80.12549396 26.33469925 97.7171194  23.82877935 31.98283424 27.94457041\n","  77.95276941 60.17662392 48.88619118 99.46450997]\n"," [91.48830833 19.09967008 47.19565063 41.00024189 13.15228867 52.22589303\n","  62.59784808 32.27262391 81.40358015 63.4433944 ]\n"," [87.73970436 85.70492716 97.91815312 93.56625204  7.23592531 67.13928549\n","   9.62537525  6.54537924 88.94381244 51.5610042 ]]\n","Best Minimum Reward Achieved: 9.625375249456171\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import random\n","\n","def calculate_min_reward(C, R):\n","    P = np.multiply(C, R)\n","    non_zero_elements = P[C == 1]\n","    return np.min(non_zero_elements) if len(non_zero_elements) > 0 else 0\n","\n","def simulated_annealing(C, R, initial_temp, cooling_rate, max_iterations):\n","    current_solution = np.random.rand(*R.shape) * 100  # Random initial solution in [0, 100]\n","    current_reward = calculate_min_reward(C, current_solution)\n","    best_solution = np.copy(current_solution)\n","    best_reward = current_reward\n","\n","    temperature = initial_temp\n","\n","    for iteration in range(max_iterations):\n","        # Create a new solution by perturbing the current solution\n","        new_solution = current_solution + (np.random.rand(*R.shape) - 0.5) * temperature\n","        new_solution = np.clip(new_solution, 0, 100)  # Keep within [0, 100]\n","\n","        new_reward = calculate_min_reward(C, new_solution)\n","\n","        # If the new solution is better, accept it\n","        if new_reward > current_reward:\n","            current_solution = new_solution\n","            current_reward = new_reward\n","\n","            # Check if it's the best solution found\n","            if new_reward > best_reward:\n","                best_solution = new_solution\n","                best_reward = new_reward\n","        else:\n","            # Accept with a probability based on temperature\n","            if random.uniform(0, 1) < np.exp((new_reward - current_reward) / temperature):\n","                current_solution = new_solution\n","                current_reward = new_reward\n","\n","        # Decrease the temperature\n","        temperature *= cooling_rate\n","\n","    return best_solution, best_reward\n","\n","# Load the channel matrix and reward matrix from CSV files\n","C_full = pd.read_csv(\"/content/drive/MyDrive/finalyr/channel_matrix.csv\", header=None).values  # Load the channel matrix\n","R_full = pd.read_csv(\"/content/drive/MyDrive/finalyr/reward_matrix.csv\", header=None).values  # Load the reward matrix\n","\n","# Select a subset size (for example, 15x15)\n","subset_size = 15  # Set this to 15 for a 15x15 matrix\n","C = C_full[:subset_size, :subset_size]\n","R = R_full[:subset_size, :subset_size]\n","\n","# Define parameters for simulated annealing\n","initial_temperature = 1000\n","cooling_rate = 0.99\n","max_iterations = 1000\n","\n","# Run simulated annealing\n","best_solution, best_reward = simulated_annealing(C, R, initial_temperature, cooling_rate, max_iterations)\n","\n","# Output results\n","print(\"Best Reward Matrix (Simulated Annealing):\")\n","print(best_solution)\n","print(\"Best Minimum Reward Achieved:\", best_reward)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kpu5zaVIQube","executionInfo":{"status":"ok","timestamp":1730607780446,"user_tz":-330,"elapsed":410,"user":{"displayName":"Sathvika Sathvi","userId":"03386786111378409958"}},"outputId":"de0d26e3-dedf-4288-d343-9fe3bd0c0016"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Best Reward Matrix (Simulated Annealing):\n","[[ 81.88855526  57.44496874  38.73707286   7.78216951  39.05618709\n","   22.37000797  27.45483083  18.66554055  15.85978128   2.28729774\n","   65.02427784  72.41467922  81.78882974  28.7958065   53.38727895]\n"," [ 97.24413781  69.43877645  25.02701406   5.70430738  29.92103\n","    4.35603947  96.26103932  39.47964526  17.34208522  11.08971023\n","    9.77168107  25.21922807  14.71341269  39.05099731  32.74712647]\n"," [ 63.45090126  50.78728952  33.88160476  75.61824827  31.074201\n","   65.38981141  17.54185779  15.07286167  39.16829089 100.\n","   90.23050984  45.02273675  89.89243263   4.98284286  81.99752975]\n"," [ 81.53056604   6.81527763   7.10793591  43.79608546  11.78729056\n","   85.50564199  13.6801157   90.96800106  11.49138177  43.19027566\n","   57.58393589  55.06767163  48.03669084  15.35079279   1.34192232]\n"," [ 88.14312706  50.11034005  53.69602801  79.16680894  63.44579237\n","    7.3710628   89.37283042  96.25826185  85.94505635  29.04230254\n","   88.35699664  15.22593528  80.38467703  33.64227828  22.7544611 ]\n"," [ 95.45309391  63.88255088  56.1521874   52.58521416  80.83900995\n","   57.38718373   4.22606004  18.26281967  23.84571692  46.37598446\n","   31.53449235  23.29832163  41.45302731  44.38752359  91.29750705]\n"," [ 33.98351273  86.82137574  40.1011579   47.70306583  51.09678254\n","   75.64977303  64.77918462   7.04017442  73.98228284  36.85735336\n","   27.69363579  40.5961307   10.63188048  67.24109168  34.9618465 ]\n"," [ 45.85874404  93.06668973  25.5395782   41.6218494    4.58923705\n","   98.49679917  36.90567969  35.30892997  37.71485528  81.81170413\n","   76.95418896  27.1392918   78.07672662  69.47965399  65.37370602]\n"," [ 59.61515334  21.7631812   60.4618798   90.37949193  50.8969071\n","   66.17432308  98.60604807  70.46627832  87.59887642  39.65157586\n","   60.45615484 100.          81.14768113   2.30844302  74.18584304]\n"," [ 52.35725677   2.77870621  43.10235149  77.71970197  75.9434007\n","    5.22570204  13.1466022   17.62373994  62.6376638   75.92251369\n","   39.88956709  49.58055278  22.7487237   21.84918442  23.49844911]\n"," [  7.263239    95.47167334  90.29086555  19.0682636   83.11716787\n","   63.57667409  57.22989847  48.20726663  16.13483882   7.34093224\n","   73.97201579  79.41523013  13.90997773  43.46322344  92.14153734]\n"," [ 84.46798609   8.66639371  14.39938374  50.67670647  13.54924682\n","   48.82678089   8.65986532  78.58401164  79.93198377  97.95068549\n","   16.73368181  64.96212455  99.83292522   4.78120126  55.96704903]\n"," [ 10.00242236  40.83125197  25.65068065  79.57479156  56.73500865\n","   78.74876486   9.00208893  11.53075853  69.51983838  70.03482452\n","    9.08898003  86.10588077  73.81044903  76.35627007  23.51602073]\n"," [ 82.94217822  60.09780707  17.15953735  72.21127772  36.87646927\n","   67.09305224  12.8379019   23.89346126   1.713782    29.1180548\n","   87.34039731  45.77073431  37.10721634  59.96241997  81.47427311]\n"," [ 67.60803657  85.32202906  71.23764881  77.42266449  27.75066169\n","   80.35237166  72.1274137   88.57925061   0.          69.27321164\n","   12.42593369  55.73147567  53.7616122    2.12335881  35.84512724]]\n","Best Minimum Reward Achieved: 2.123358812582728\n"]}]}]}